\documentclass{sig-alternate}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\newcommand{\superscript}[1]{\ensuremath{^{\textrm{#1}}}}
\def\sharedaffiliation{\end{tabular}\newline\begin{tabular}{c}}
\def\wu{\superscript{*}}
\def\wg{\superscript{\dag}}

\usepackage{listings} 

% Typography
\usepackage{times}
\usepackage{mathptmx}
\usepackage{microtype}
\usepackage[normalem]{ulem}
\usepackage[pdftex,bookmarks,bookmarksopen,bookmarksdepth=2,
            urlcolor=black,colorlinks=true,linkcolor=black,citecolor=black]{hyperref}
\usepackage[capitalize,noabbrev]{cleveref}
\def\UrlFont{\em}

% Graphics
\usepackage{tikz}
\usepackage{tkz-graph}
\usetikzlibrary{arrows,positioning,shapes.misc}
\usepackage{graphicx}
\definecolor{lightgrey}{RGB}{170, 170, 170}
\definecolor{darkblue}{RGB}{0, 0, 0}
\definecolor{darkred}{RGB}{170, 0, 0}
\definecolor{darkgreen}{RGB}{0, 110, 0}

% Acronyms
\usepackage{xspace}
\newcommand{\sparql}{{SPARQL}\xspace}
\newcommand{\sparqlo}{{SPARQL 1.1}\xspace}
\newcommand{\arq}{{ARQ}\xspace}
\newcommand{\wthreec}{{W\oldstylenums 3C}\xspace}
\newcommand{\sfive}{{S\oldstylenums 5}\xspace}
\newcommand{\select}{{SELECT}\xspace}
\newcommand{\construct}{{CONSTRUCT}\xspace}
\newcommand{\ask}{{ASK}\xspace}
\newcommand{\describe}{{DESCRIBE}\xspace}
\newcommand{\from}{{FROM}\xspace}
\newcommand{\odbc}{{odbc}\xspace}

% Tight lists
\usepackage{enumitem}
\setlist{nolistsep}

% Listings and Verbatim environment
\usepackage{fancyvrb}
\usepackage{relsize}
\usepackage{listings}
\usepackage{verbatim}
\newcommand{\smalllistingsize}{\fontsize{8pt}{9.5pt}}
\newcommand{\inlinelistingsize}{\fontsize{8.5pt}{11pt}}
\newcommand{\defaultlistingsize}{\inlinelistingsize}
\RecustomVerbatimCommand{\Verb}{Verb}{fontsize=\inlinelistingsize}
\RecustomVerbatimEnvironment{Verbatim}{Verbatim}{fontsize=\inlinelistingsize}
\lstset{frame=lines,captionpos=b,numberbychapter=false,escapechar=ยง,
        belowskip=1em,
        xleftmargin=2ex,
        framexleftmargin=2ex,
        basicstyle=\ttfamily\smalllistingsize\selectfont}
\crefname{lstlisting}{Listing}{Listings}
\definecolor{grey}{RGB}{130,130,130}

\usepackage{color}
\newcommand{\todo}[1]{\noindent\textcolor{red}{{\bf \{TODO}: #1{\bf \}}}}
\begin{document}

\title{Studying public transit API query logs\\ to get an indication of travel flows}
\numberofauthors{6}
\author{
\alignauthor
Pieter Colpaert\\
\affaddr{\email{\texttt{pieter.colpaert@ugent.be}}}
\and
\alignauthor
Alvin Chua\\
\affaddr{\email{\texttt{alvin.chua@asro.kuleuven.be}}}
\and
\alignauthor
Ruben Verborgh\\
\affaddr{\email{\texttt{ruben.verborg@ugent.be}}}
\and
\alignauthor
Erik Mannens\\
\affaddr{\email{\texttt{erik.mannens@ugent.be}}}
\and
\alignauthor
Rik Van de Walle\\
\affaddr{\email{\texttt{rik.vandewalle@ugent.be}}}
\and
\alignauthor
Andrew Vande Moere\\
\affaddr{\email{\texttt{andrew.vandemoere\\@asro.kuleuven.be}}}\\
}

\maketitle
\begin{abstract}
% Context
%Public transit schedules are made available on the Web in various ways, such as in a GTFS file, a route planning API, or through Linked Connections.
The iRail project hosts a route planning API for the Belgian railway company.
This webservice provides an answer to a route planning question with parameters such as ``departuretime'', ``from'' and ``to''.
% Need
In the field of urban planning, researchers need an indication of how people move between cities. 
%Yet, getting this data from official sources has proven to be troublesome.
% Task
In this paper, we analyse the query logs of the iRail API, to see whether it can tell us something about travel flows between cities in Belgium.
% Object
We studied queries for the year 2013, which contains an average of $\sim3000$ interesting queries per day ($\sim0.4\%$ of the amount of passengers per weekday).
% Findings
We illustrate \todo{X} interesting patterns that correspond to reality and we show an outlier in the data.
% Conclusion
We could not find a way \todo{to validate \ldots}, yet more research is needed to understand how representative for travel flows they may be.
% Perspectives
In earlier work, we suggested the Linked Data Fragments axis to discuss new approaches to publish queryable public transit data.
Now, we suggest a discussion for gathering query logs when using Linked Data Fragments approaches.

\end{abstract}

\vspace{1em}

\section{Introduction}
\label{sec:introduction}

\todo{Rework introduction at the end}

Today, public transport data still remains absent from the Linked Open Data cloud\footnote{\url{http://lod-cloud.net/}}.
Bizarre, one could notice, as many open transport datasets are already available, according to the Global Open Data Index of 2014\footnote{\url{http://index.okfn.org/dataset/timetables/2014/}}.
We can imagine that, what contributed to this, are the de-facto standard ways to publish public transit data to the Web.
There are currently two ways, as illustrated in \cref{fig:LDFAxis1}: publishing data using the General Transit Feed Specification (GTFS) and offering a route planning service.

\emph{GTFS}, on the one hand, is a data dump format: it is a compressed ZIP-file, containing a couple of CSV-files, describing the rules for when a public transit vehicle will pass by on a certain location.
The specification is a huge success: up to date, it is supported among all current open source route planning software systems, and it is used in products such as \emph{CityMapper}, \emph{Ally}, \emph{Navitia.io}, \emph{Google Maps} and \emph{Bing Maps}.
Persistence of the identifiers used within these datasets, is not a requirement, neither is it an ambition of the format\footnote{\url{https://groups.google.com/forum/#!msg/gtfs-changes/Z8Mf31MaZms/8Hc9F4psAQAJ}}.
The goal of GTFS is to create an exchange format which specific software packages can use to transform it into their format of choice.

On the other hand, public transit agencies also publish their data by providing \emph{route planners}.
These route planner offer a query service on top of the data and expose these over the Web.
However, when machines should access these, rate limiters are common place: only a limited amount of queries should be done in order for the service to be able to stay online.

\input{ldfaxis1}

Getting indications of people flows through public transit networks is a challenge.
The data is tedious to get, mainly with public transit systems where passengers don't have to check-in and check-out.
Nevertheless, people are calculating their intended routes by using the Web.
\emph{Can we get an indication of these transit flows by studying the query logs of Web-services?}

The \emph{iRail} project\footnote{\url{http://hello.irail.be}} started in 2008 to make the data of the Belgian railway accessible for developers.
Ever since, the project offers developer both a GTFS data dump for third party apps and a route planning API.
The query logs of this API has been stored since 2013.
Our hypothesis is that, while we should study the data with high level of sceptisicm (given enough data, you can find any pattern), our data will be better than random data.

In this paper, we give a small overview of related work to gather data for flow analysis.
Next, we study the iRail query logs to find out whether we can find interesting patterns.
Finally, we look at Linked Connections~\cite{lc}, a proposed new way of publishing queryable public transit data, and whether we would still be able to have an indication of the transit flows with a Linked Data Fragments~\cite{ldf} approach.

\section{Related work}
\label{sec:relwork}

\todo{Write relwork at the end}

\emph{Flow analysis} is a topic of theoretical interest and practical importance in various disciplines. 
Flow analysis is conventionally conducted to study spatial dynamics and identify routine patterns in the movement of people.
For instance, interest in modelling traffic flows emerged from the strain placed on urban transportation systems during peak hours~\cite{roth,ferreira}.
Likewise, insight into routine travel patterns is crucial for the conceptualisation of functional urban areas~\cite{servillo,sykora}, urban hierarchies~\cite{christaller} and other territorial structures.

Over the past decade, large datasets have become increasingly commonplace due to the proliferation of sensor networks and portable devices like smartphones.
Termed ``Big Data'' due to the large volume of data records that emerge from real-time sensing\cite{kitchin}, such datasets typically contain information of activities or processes linked to the space and time where they occur.
In the domain of ``Smart City'' research, much has been accomplished with the use of ``Big Data'' to monitor human movement.
Smart card data from public transport systems~\cite{roth,beecham}, taxi journeys~\cite{ferreira} as well as cellular call data~\cite{sevtsuk} have provided planners with new opportunities to develop greater understanding of mobility patterns in urban environments~\cite{batty}.

\section{The logs}
\label{sec:logs}

In 2013, we started to use a MySQL table to store each request to the iRail API in a table, including User-Agent string, the timestamp, whether or not the request succeeded, the departure station and the desired station of arrival.
From an export of this table, we filtered out only the route plannning queries that succeeded for the entire year.
The resulting dataset, used for the rest of this paper, can be downloaded at \todo{\url{http://datawijs.be/apilog.tar.gz}}.

We cleaned this data by removing the requests done by harvesters or search engine bots.
Thanks to the user agents, this was a fairly straight-forward operation.
The remainder of the file delivers an average of 3000 route planning queries a day, which we can use an an indication of travel intensities.
Taking into account that 758,370 people take the train each day on a weekday (according to the railway network maintainer Infrabel) and assuming that each query is a trip done by a certain passenger, this sample equals $\sim0.4\%$ of the railway users in Belgium.

As of the 17th of December 2015, iRail publishes the most recent 1000 requests done on the API as open data, each second, at \url{http://api.irail.be/logs/}.
This amounts today to an average of 86k queries to the API per day, as the API gained popularity thanks to apps like \emph{BeTrains}\footnote{\url{https://play.google.com/store/apps/details?id=tof.cv.mpp}} and \emph{Railer}\footnote{\url{http://railer.be/}}.
On average, 14,357 of these are valid route planning queries (others include departures in a station, status of a vehicle, or a list of all stations).
If each query would amount to indeed 1 passenger, this would today be equal to almost 2\% of all passengers.
As we only gathered a small sample of this data by today, we didn't use the data of 2015, but used the data of 2013 instead, at the time when our servers didn't have caches in place.

As we are dealing with query logs, privacy becomes an issue~\cite{silvestri}.
However, we do not publish the IP addresses with each query, which makes it hard to track single users.
To remove all doubt, we have asked and received the consent of the privacy commission of Belgium.

\section{Method}
\label{sec:method}

\subsection{Processing}
\todo{Each data record contains the names of both origin and destination (OD) stations, the user agent that made the query todo: Pieter this needs definition, as well as the time when the query was made.

As we were specifically interested in examining morning rush hour travel on weekdays, we filtered the dataset to exclude data records created outside the range of xxx hrs and xxx hrs on weekdays, and all data records created over the weekends.

The iRail API serves a wide range of  applications that vary in terms of software architecture and functionality. End user applications such as BeTrains and Railer Pieter xxx and xxx query for time schedules when explicitly directed by the user. On the other hand, automated services like xxx make routine queries to gather data for further computation. Naturally, such automated queries are detected based on xxx. 

We exclude all automated queries to refine the dataset and remove potential bias.

Queries made by automated user agents like xxx and xxx were also excluded from the dataset to remove biases that may over represent connections between certain stations.

Additionally, data records with unparsable origin or destination station names due to spelling mistakes or invalid character encoding were also removed from the data set.}

\subsection{Visualization}

\todo{Alvin}

\section{Results}
\label{sec:results}

\begin{figure}
\centering
\includegraphics[width=8.1cm,align=center]{histogram}
\caption{Histogram of one weekday}
\label{fig:brussels}
\end{figure}

In this chapter, we report on the results of studying visualizations with experts of Trein Tram Bus, a not for profit passenger federation.

\subsection{Commuting pattern}

We see people leaving in the morning and return in the evening (see \cref{fig:brussels} and todo)

The pair of chord diagrams in \cref{fig:brussels,fig:antwerp} capture the aggregated number of queries made between any two stations on weekdays and weekends between 6 to 9 in the morning.
The chords that link two distinct stations, are coloured coded by region and proportionately scaled to the number of queries from a station of origin to a destination.
For instance, approximately 3,530 queries were made from Leuven to Brussels than in the opposite direction (approximately 1,530) on weekdays.
Reading both diagrams in this manner reveals the complexity of movement on the rail system and the significance of cities in daily travel.
Brussels serves as the principal centre of rail activity in general, yet its centrality is more distinctive for the walloon region than Flanders.
Queries from Walloonia with exception to Liege, are generally made from provincial stations towards Brussels instead of their respective provincial capitals.
Queries in Flanders, on the hand, tend to be distributed among major cities otherwise known as the Flemish Diamond, a network of four metropolitan areas in Belgium comprised of Ghent, Brussels, Antwerp and Leuven.
The difference between both patterns appear to correspond with existing measures of population density, providing valuable insight and alternative perspectives into the function of cities in rural and urban settings.

\subsection{Flanders is polycentric, Wallonia monocentric}

We can also observe the effect of "density" in Flanders where people move from the rural towards cities. Look at weekday-mornings: commuting towards Gent, Brussels, Antwerp. This is not as obvious in the Walloon region (except for Liege). The reverse occurs on weekday-evenings. Local patterns can also be observed and this corresponds to what we know: ``cities are the central hubs''.
Walloon region: everything converges on Brussels

\subsection{Inexplicable results}

We also see weird things happening in Antwerp, where a large amount of people go to the province in the morning on weekdays, while the oposite happens in Liege.
When looking into the data, the Antwerp pattern appears due to one specific route which is queried each morning.
Is there a group of colleagues all using the same app taking the same train daily?
Is it someone who checks this trip over and over again for delays?
We can only guess\ldots

\begin{figure}
\centering
\includegraphics[width=8.1cm,align=center]{brussels}
\caption{Pair of chord visualization of the city of Brussels: transit flows towards Brussels from elsewhere in Belgium and vice versa.}
\label{fig:brussels}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=8.1cm,align=center]{antwerp}
\caption{Pair of chord visualization of the city of Antwerp: transit flows towards Antwerp from elsewhere in Belgium and vice versa.}
\label{fig:antwerp}
\end{figure}

\section{Publishing transport data: the impact on query logs}
\label{sec:publishing}

Publishing public transport data today happens in two ways: by publishing a data dump of the timetables or by hosting a public route planning service.
Linked Data Fragments~\cite{ldf} is a way to think about data publishing as a set of trade-offs between client and servers.
These trade-offs can be mapped on an axis, cfr. \cref{fig:LDFAxis2}, in which the 2 extremes are identified as: the client does all the processing by downloading all the data at once, versus the server does all the processing by exposing \emph{expressive} APIs.
Linked Connections~\cite{lc} proposes other ticks on this axis.
By publishing fragments of the data needed for by the shortest path algorithm, the algorithm can be executed on the client.
Furthermore, it lowers to load on the server, and it enables clients to federate queries over different servers, including different regions, transit modes and user's need.

%label: fig:LDFAxis2
\input{ldfaxis2}

The expressivity of the server also affects the way logs can be gathered.
When the server becomes less expressive, e.g., when it only allows to set a departure station and a departure time, then the server doesn't know the arrival station, which makes it harder to get an indication of the travel flow.

\todo{Also in USEWOD2014 there was a paper on LDF and how we could know which SPARQL queries needed to be solved}

%\subsection{Intermodal route planning}


\section{Conclusion and discussion}
\label{sec:conclusion}

The contribution of this paper is twofold.
For the first time, we studied query logs to find travel patterns.
Due to lack of information we could not evaluate our results, yet the visualizations look promising...
There are obvious caveats associated with the use of such data as proxy for actual statistical counts. 
For instance, the data only captures an intention of a passenger: it's unsure whether the person actually took the train.
Furthermore, different requests could be done by one person with an intention to travel.
On top of that, our sample used for this paper can only represent a maximum of 0.4\% of the daily traffic flow.

The second contribution is our position that we suggest to decouple the query logs from the query execution.

% Fix spacing after References header (as line 1308 of sig-alternate.cls breaks it)
\let\oldsection\section
\renewcommand{\section}[2][1]{\oldsection{#1}\vspace{-3pt}}

\bibliographystyle{abbrv}
\bibliography{refs}
\end{document}
