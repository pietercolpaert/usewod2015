\documentclass{sig-alternate}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\newcommand{\superscript}[1]{\ensuremath{^{\textrm{#1}}}}
\def\sharedaffiliation{\end{tabular}\newline\begin{tabular}{c}}
\def\wu{\superscript{*}}
\def\wg{\superscript{\dag}}

\usepackage{listings} 

% Typography
\usepackage{times}
\usepackage{mathptmx}
\usepackage{microtype}
\usepackage[normalem]{ulem}
\usepackage[pdftex,bookmarks,bookmarksopen,bookmarksdepth=2,
            urlcolor=black,colorlinks=true,linkcolor=black,citecolor=black]{hyperref}
\usepackage[capitalize,noabbrev]{cleveref}
\def\UrlFont{\em}

% Graphics
\usepackage{tikz}
\usepackage{tkz-graph}
\usetikzlibrary{arrows,positioning,shapes.misc}
\usepackage{graphicx}
\definecolor{lightgrey}{RGB}{170, 170, 170}
\definecolor{darkblue}{RGB}{0, 0, 0}
\definecolor{darkred}{RGB}{170, 0, 0}
\definecolor{darkgreen}{RGB}{0, 110, 0}

% Acronyms
\usepackage{xspace}
\newcommand{\sparql}{{SPARQL}\xspace}
\newcommand{\sparqlo}{{SPARQL 1.1}\xspace}
\newcommand{\arq}{{ARQ}\xspace}
\newcommand{\wthreec}{{W\oldstylenums 3C}\xspace}
\newcommand{\sfive}{{S\oldstylenums 5}\xspace}
\newcommand{\select}{{SELECT}\xspace}
\newcommand{\construct}{{CONSTRUCT}\xspace}
\newcommand{\ask}{{ASK}\xspace}
\newcommand{\describe}{{DESCRIBE}\xspace}
\newcommand{\from}{{FROM}\xspace}
\newcommand{\odbc}{{odbc}\xspace}

% Tight lists
\usepackage{enumitem}
\setlist{nolistsep}

% Listings and Verbatim environment
\usepackage{fancyvrb}
\usepackage{relsize}
\usepackage{listings}
\usepackage{verbatim}
\newcommand{\smalllistingsize}{\fontsize{8pt}{9.5pt}}
\newcommand{\inlinelistingsize}{\fontsize{8.5pt}{11pt}}
\newcommand{\defaultlistingsize}{\inlinelistingsize}
\RecustomVerbatimCommand{\Verb}{Verb}{fontsize=\inlinelistingsize}
\RecustomVerbatimEnvironment{Verbatim}{Verbatim}{fontsize=\inlinelistingsize}
\lstset{frame=lines,captionpos=b,numberbychapter=false,escapechar=ยง,
        belowskip=1em,
        xleftmargin=2ex,
        framexleftmargin=2ex,
        basicstyle=\ttfamily\smalllistingsize\selectfont}
\crefname{lstlisting}{Listing}{Listings}
\definecolor{grey}{RGB}{130,130,130}

\usepackage{color}
\newcommand{\todo}[1]{\noindent\textcolor{red}{{\bf \{TODO}: #1{\bf \}}}}
\newdef{definition}{Definition}

\begin{document}

\title{Studying public transit API query logs\\ to get an indication of travel flows}
\numberofauthors{6}
\author{
\alignauthor
Pieter Colpaert\\
\affaddr{\email{\texttt{pieter.colpaert@ugent.be}}}
\and
\alignauthor
Alvin Chua\\
\affaddr{\email{\texttt{alvin.chua@asro.kuleuven.be}}}
\and
\alignauthor
Ruben Verborgh\\
\affaddr{\email{\texttt{ruben.verborg@ugent.be}}}
\and
\alignauthor
Erik Mannens\\
\affaddr{\email{\texttt{erik.mannens@ugent.be}}}
\and
\alignauthor
Rik Van de Walle\\
\affaddr{\email{\texttt{rik.vandewalle@ugent.be}}}
\and
\alignauthor
Andrew Vande Moere\\
\affaddr{\email{\texttt{andrew.vandemoere\\@asro.kuleuven.be}}}\\
}

\maketitle
\begin{abstract}

%Public transit schedules are made available on the Web in various ways, such as in a GTFS file, a route planning API, or through Linked Connections.
%This webservice provides an answer to a route planning question with parameters such as ``departuretime'', ``from'' and ``to''.
% Context & % Need
In the field of urban planning, researchers need an indication of how people move between cities. 
Yet, getting statistics of travel flows within public transit systems has proven to be troublesome.
% Task
We analyzed the query logs of the iRail API, a high expressive route planning API for the Belgian railways, to get an indication of travel flows between cities in Belgium.
We were able to study $\sim$100k to 500k requests for each month between October 2012 and November 2015, which is between $0.5\%$ and $1.7\%$ of the amount of monthly passengers.
% Object & Findings
Using data visualizations, we illustrated the commuting patterns in Belgium and show that Brussels, the capital, acts as a central hub. The Flemish region appears to be polycentric, while in the Walloon region, everything converges on Brussels.
The findings correspond to the real travel demand, say experts of the passenger federation Trein Tram Bus.
% Conclusion
We conclude that query logs of route planners are of high importance in getting an indication of the travel flows.
% Perspectives
High expressive transport data publishing methods such as route planning API exist, as well as low expressive data dumps or data fragments.
In order to be able to gather meaningful logs in all cases, we suggest using a separate POST request containing the entire query.

\end{abstract}

\vspace{1em}

\section{Introduction}
\label{sec:introduction}

\todo{Rework introduction at the end}

%Today, public transport data still remains absent from the Linked Open Data cloud\footnote{\url{http://lod-cloud.net/}}.
%Bizarre, one could notice, as many open transport datasets are already available, according to the Global Open Data Index of 2014\footnote{\url{http://index.okfn.org/dataset/timetables/2014/}}.
%We can imagine that, what contributed to this, are the de-facto standard ways to publish public transit data to the Web.
%There are currently two ways, as illustrated in \cref{fig:LDFAxis1}: publishing data using the General Transit Feed Specification (GTFS) and offering a route planning service.

%\emph{GTFS}, on the one hand, is a data dump format: it is a compressed ZIP-file, containing a couple of CSV-files, describing the rules for when a public transit vehicle will pass by on a certain location.
%The specification is a huge success: up to date, it is supported among all current open source route planning software systems, and it is used in products such as \emph{CityMapper}, \emph{Ally}, \emph{Navitia.io}, \emph{Google Maps} and \emph{Bing Maps}.
%Persistence of the identifiers used within these datasets, is not a requirement, neither is it an ambition of the format\footnote{\url{https://groups.google.com/forum/#!msg/gtfs-changes/Z8Mf31MaZms/8Hc9F4psAQAJ}}.
%The goal of GTFS is to create an exchange format which specific software packages can use to transform it into their format of choice.

%On the other hand, public transit agencies also publish their data by providing \emph{route planners}.
%These route planner offer a query service on top of the data and expose these over the Web.
%However, when machines should access these, rate limiters are common place: only a limited amount of queries should be done in order for the service to be able to stay online.

%\input{ldfaxis1}

Getting indications of people flows through public transit networks is a challenge.
The data is tedious to get, mainly with public transit systems where passengers don't have to check-in and check-out.
Nevertheless, people are calculating their intended routes by using the Web.
\emph{Can we get an indication of these transit flows by studying the query logs of Web-services?}

The \emph{iRail} project\footnote{\url{http://hello.irail.be}} started in 2008 to make the data of the Belgian railway accessible for developers.
Ever since, the project offers developer both a GTFS data dump for third party apps and a route planning API.
The query logs of this API has been stored since 2013.
We study these query logs by creating a couple of visualizations which illustrate a couple of patterns.
Two of the documented patterns in this paper correspond to reality, another does not.

In this paper, we give a small overview of related work to gather data for flow analysis.
Next, we study the iRail query logs to find out whether we can find interesting patterns.
Finally, we look at Linked~Connections~\cite{lc}, a proposed new way of publishing queryable public transit data, and whether we would still be able to have an indication of the transit flows with a Linked Data Fragments~\cite{ldf} approach.

\section{Related work}
\label{sec:relwork}

\todo{Write relwork at the end}

\emph{Flow analysis} is a topic of theoretical interest and practical importance in various disciplines. 
Flow analysis is conventionally conducted to study spatial dynamics and identify routine patterns in the movement of people.
For instance, interest in modelling traffic flows emerged from the strain placed on urban transportation systems during peak hours~\cite{roth,ferreira}.
Likewise, insight into routine travel patterns is crucial for the conceptualisation of functional urban areas~\cite{servillo,sykora}, urban hierarchies~\cite{christaller} and other territorial structures.

Over the past decade, large datasets have become increasingly commonplace due to the proliferation of sensor networks and portable devices like smartphones.
Termed ``Big Data'' due to the large volume of data records that emerge from real-time sensing\cite{kitchin}, such datasets typically contain information of activities or processes linked to the space and time where they occur.
In the domain of ``Smart City'' research, much has been accomplished with the use of ``Big Data'' to monitor human movement.
Smart card data from public transport systems~\cite{roth,beecham}, taxi journeys~\cite{ferreira} as well as cellular call data~\cite{sevtsuk} have provided planners with new opportunities to develop greater understanding of mobility patterns in urban environments~\cite{batty}.

\section{The logs}
\label{sec:logs}

The iRail API is a XML/JSON HTTP API in which one request on \url{http://api.irail.be} will result in a response that can be used directly in an end-user app.
It contains four features: a route planning query (\url{http://api.irail.be/connections/{?from,to,date,time}}), a query for the next departures in a certain station (\url{http://api.irail.be/liveboard/{?station,date,time}}), a query for the status of a certain train (\url{http://api.irail.be/vehicle/{?id,date}}) and a query for a list of all stations (\url{http://api.irail.be/stations/}).
We have gathered the \emph{Apache} \emph{access.log} files 
\begin{itemize}
  \item the timestamp,
  \item whether or not the request succeeded,
  \item the path of the query (e.g., \emph{/connections/?from=Ghent\&to=Antwerp}) and
  \item the User-Agent (cfr. RFC2616\footnote{The User-Agent request-header field contains information about the user agent originating the request. This is for statistical purposes, the tracing of protocol violations, and automated recognition of user agents for the sake of tailoring responses to avoid particular user agent limitations -- \url{http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html}})
\end{itemize}

\begin{figure}
\centering
\includegraphics[width=8.6cm]{querylogs}
\caption{Amount of queries on the route planning part of the iRail API between 2012 and 2016. In April 2015 an official app of the Belgian railways was discontinued, which explains the sudden raise of iRail API queries.}
\label{fig:querylogs}
\end{figure}

From an export of this table, we filtered out only the route plannning queries that succeeded for the entire year.
The resulting dataset, used for the rest of this paper, can be downloaded at \todo{\url{http://datawijs.be/apilog.tar.gz}}.

As we are dealing with query logs, privacy becomes an issue~\cite{silvestri}.
However, we do not publish the IP addresses with each query, which makes it hard to track single users.
To remove all doubt, we have asked and received the consent of the privacy commission of Belgium, which declared we can study the logs without any restrictions.

\begin{figure}
\centering
\includegraphics[width=8.6cm]{avg-all}
\caption{Distribution of iRail route planning API queries on average per day of the week between 2012 and 2016}
\label{fig:average}
\end{figure}

%\begin{figure}
%\centering
%\includegraphics[width=8.3cm]{dec21}
%\caption{Comparison of route planning queries on December 21st 2015 with the average on a Monday between 2012 and 2016. Whilst being a school holiday, there is no notable difference, except for the peek hours being a bit later, }
%\label{fig:dec21}
%\end{figure}

\begin{figure}
\centering
\includegraphics[width=8.6cm]{dec24}
\caption{Comparison of route planning queries on December 24th (Christmass eve) 2015 with the average on a Thursday between 2012 and 2016. The illustration shows that people started going home earlier than usual.}
\label{fig:dec24}
\end{figure}

\section{Method}
\label{sec:method}


\subsection{Processing}

We cleaned the logs by removing the requests done by harvesters or search engine bots.
Thanks to the user agents, this was a fairly straight-forward operation.
\todo{The remainder of the file delivers an average of 3000 route planning queries a day, which we can use an an indication of travel intensities.
Taking into account that 758,370 people take the train each day on a weekday (according to official number of the Belgian Railway company in 2013\footnote{\url{http://www.treintrambus.be/images/OpstappendeReizigers_2013_2.pdf}}) and assuming that each query is a trip done by a certain passenger, this sample equals $\sim0.4\%$ of the railway users in Belgium.}\footnote{Calculated by using indicators of the Flemish government and extrapolating the numbers for 2015 \url{http://www4.vlaanderen.be/sites/svr/Cijfers/Exceltabellen/mobiliteit/vervoersprestaties/personenvervoer/MOBIOPEN006.xls}}

Each data record contains the names of both origin and destination (OD) stations, the user agent that made the query, as well as the time when the query was made.
As we were specifically interested in studying morning and evening rush hour travel that occur on weekdays, we filtered the dataset to exclude data records created outside the time range of 06:00~hrs and 10:00~hrs as well as 17:00~hrs and 21:00~hrs on weekdays, and all data records created on weekend. Queries made by automated user agents like search engine bots and data harvesters were also excluded from the dataset to remove biases that may over represent connections between certain stations. Similarly, data records with unparsable origin or destination station names due to spelling mistakes or invalid character encoding were removed as well.

The data is then simplified so that province level flow patterns are emphasised.
\cref{fig:brussels} provides a diagrammatic representation of the procedure.
First, both origin and destination stations for each data record are spatially aggregated based on provincial administrative boundaries (See Figure xa).
If an origin or destination station is a located outside of Belgium, it is considered international travel and aggregated in a distinct group (See Figure xb).
Train stations in major cities are excluded from aggregation so that the volume of flow between provinces and major cities are comparable (See Figure xc).
The following types of flows are observable from the outcome of aggregation:

\begin{itemize}
  \item Travel from any provincial station to a major city.
  \item Travel between any two major cities.
  \item Travel between any two provincial stations.
  \item Travel between any international station to a major city.
  \item Travel between any international station to a provincial station.
\end{itemize}

\subsection{Visualization}

\todo{Alvin}

Visualisation is frequently used to make data analysis tangible, so that the results can be communicated and debated \todo{Robinson, 2008 -121}. This is crucial for our research since the questions presented are exploratory in nature \todo{Kraak, 2008 -150} and can be addressed in many ways. Movement data has received substantial attention from the visualisation community and a range of techniques has been developed to support analysis \todo{Andrienko, 2012 -196}. Of these techniques, flow visualisations facilitate the comparison of aggregated movement over space and time. There are three types of flow visualisations: Line based representations preserves the complete trajectory while matrix type representations take only the start and end locations into account.

Line based representations indicate movement on a path with the shape of the line. The thickness of each line is scaled to the volume of flow along a path. The direction of flow is commonly indicated with an arrowhead. This representation is detailed and straightforward to understand but becomes cluttered when lines intersect. A number of solutions have been proposed for clutter reduction. Filtering is the most commonly practiced. The same goal can be achieved by clustering lines that have similar properties like common start, end or intermediate locations \todo{Andrienko, 2007 -198}. Hierarchical \todo{Guo, 2009 -199} and density based \todo{Rinzivillo, 2008 -201} clustering have also been introduced for this purpose. Both solutions are effective at reducing clutter yet it should be noted that excessive aggregation or filtering removes a significant amount of information from the visualisation. Another solution to reduce clutter is to transform the visual representation. This is achieved by rerouting \todo{Phan, 2005 -88} or bundling \todo{Hurter, 2014 -200} lines in close proximity so that they appear grouped. Unlike clustering, this solution changes the shape of lines by way of interpolation to obtain an ideal layout. In most cases, the interpolation is regulated by conditions to avoid intersections and follow key geographic features such as roads, rivers or coastlines so that the layout appears natural. This solution emphasises major flows within the visualisation since large groups gain visual dominance. Nonetheless, there are two drawbacks to this solution. First, short distance flows that may be important at local scales are de-emphasised or lost in the transformation. Next, the lines do not depict actual paths of movement thus this solution may not be suitable for applications that require strict geographic accuracy.

Matrix type representations are frequently used when the origin and destination preside over intermediate locations on the path of movement. This type of representation is referred to as origin-destination (OD) matrix. Rows and columns correspond to locations while cells are coloured to express the volume of flow. OD matrices can be reordered to emphasise connectivity between locations but the lack of geographic context is a distinct disadvantage. Several solutions have been developed to address this shortcoming. These are based on the notion of small multiples: The matrix is arranged in a geographical order so that the cells correspond to locations on the map. Then, a smaller map of the geographical context is nested in each cell to enable more intuitive comparisons \todo{Guo, 2006 -202}. The limitation of this solution is similar to other forms or small multiples in general - the layout space allocated to each nested map becomes smaller as the number of cells increase. In this instance, nesting detailed geographical maps is problematic since majority of the geographical features become illegible due to scaling. OD Map \todo{Wood, 2010 -86} proposes to nests a series of geographically ordered matrices that are more expressive of spatial relations and remain legible even when a small amount of layout space allocated to each cell.

\section{Results}
\label{sec:results}

In this chapter, we report on the results of studying visualizations with experts of Trein Tram Bus, a not for profit passenger federation.

\subsection{Commuting pattern}

We see people leaving in the morning and return in the evening (see \cref{fig:brussels} and todo)

The pair of chord diagrams in \cref{fig:brussels,fig:antwerp} capture the aggregated number of queries made between any two stations on weekdays and weekends between 6 to 9 in the morning.
The chords that link two distinct stations, are coloured coded by region and proportionately scaled to the number of queries from a station of origin to a destination.
For instance, approximately 3,530 queries were made from Leuven to Brussels than in the opposite direction (approximately 1,530) on weekdays.
Reading both diagrams in this manner reveals the complexity of movement on the rail system and the significance of cities in daily travel.
Brussels serves as the principal centre of rail activity in general, yet its centrality is more distinctive for the walloon region than Flanders.
Queries from Walloonia with exception to Liege, are generally made from provincial stations towards Brussels instead of their respective provincial capitals.
Queries in Flanders, on the hand, tend to be distributed among major cities otherwise known as the Flemish Diamond, a network of four metropolitan areas in Belgium comprised of Ghent, Brussels, Antwerp and Leuven.
The difference between both patterns appear to correspond with existing measures of population density, providing valuable insight and alternative perspectives into the function of cities in rural and urban settings.

\subsection{Flanders is polycentric, Wallonia monocentric}


\begin{figure}
\centering
\includegraphics[width=8.1cm]{brussels}
\caption{Pair of chord visualization of the city of Brussels: transit flows towards Brussels from elsewhere in Belgium and vice versa.}
\label{fig:brussels}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=8.1cm]{antwerp}
\caption{Pair of chord visualization of the city of Antwerp: transit flows towards Antwerp from elsewhere in Belgium and vice versa.}
\label{fig:antwerp}
\end{figure}

We can also observe the effect of "density" in Flanders where people move from the rural towards cities. Look at weekday-mornings: commuting towards Gent, Brussels, Antwerp. This is not as obvious in the Walloon region (except for Liege). The reverse occurs on weekday-evenings. Local patterns can also be observed and this corresponds to what we know: ``cities are the central hubs''.
Walloon region: everything converges on Brussels

\subsection{Inexplicable results}

We also see weird things happening in Antwerp, where a large amount of people go to the province in the morning on weekdays, while the oposite happens in Liege.
When looking into the data, the Antwerp pattern appears due to one specific route which is queried each morning.
Is there a group of colleagues all using the same app taking the same train daily?
Is it someone who checks this trip over and over again for delays?
We can only guess\ldots

\section{Publishing transport data}
\label{sec:publishing}

%It is in the interest of public transit agencies that the use of their time schedule data is maximized.
%We can imagine that when more people are informed about the agency's offer, there will be a higher amount of people that will use the service.
%There are currently two ways to publish transit data, as illustrated in \cref{fig:LDFAxis2}: publishing data using the General Transit Feed Specification (GTFS) and offering a route planning service.

%\emph{GTFS}, on the one hand, is a data dump format: it is a compressed ZIP-file, containing a couple of CSV files, describing the rules for when a public transit vehicle will pass by on a certain location.
%GTFS is supported among all current open source route planning software systems and it is used in products/apps such as \emph{CityMapper}, \emph{Ally}, \emph{Navitia.io}, \emph{Google Maps} and \emph{Bing Maps}.
%Persistence of the identifiers used within these datasets, is not a requirement, neither is it an ambition of the format\footnote{\url{https://groups.google.com/forum/#!msg/gtfs-changes/Z8Mf31MaZms/8Hc9F4psAQAJ}}.
%The goal of GTFS is to create an exchange format which specific software packages can use to transform it into their format of choice.

%On the other hand, public transit agencies also publish their data by providing \emph{route planners} such as the French railway company\footnote{\url{http://tech.eu/features/7119/sncf-api-real-time-data/}}, the Dutch railway company\footnote{\url{http://www.ns.nl/reisinformatie/ns-api}} or \ldots\footnote{\url{http://otherapiofadifferentagency}}
%These route planner offer a query service on top of the data and expose these over the Web.
%In this paper we have studied the query logs of such an \emph{expressive} route planning API, which per request offers an interesting log entry.


%label: fig:LDFAxis2
\input{ldfaxis2}

%Linked Data Fragments~\cite{ldf} is a way to think about data publishing as a set of trade-offs between client and servers.
%These trade-offs can be visualized on the axis in \cref{fig:LDFAxis2}: ticks in between the extremes indicate different client/server options.
%For route planning systems, we call these other ticks Linked~Connections~\cite{lc}: 
%by publishing fragments of the data needed by an earliest arrival time algorithm, the algorithm can be executed by a user agent while the downloading the data.
%An example of such an implementation is illustrated in \cref{fig:lc}.
%By exploiting the caching mechanisms behind HTTP, it lowers to load on the server, making it easier to keep the data high available.
%Furthermore, it enables clients to federate queries over different servers representing different regions, transit modes or different user requirements such as low criminality rates or wheelchair accessibility.


%\begin{figure}[h]
%    \centering
%    \includegraphics[width=0.48\textwidth]{LC}
%    \caption{An example implementation of a route planning algorithm: fragments of data needed by a route planning algorithm are published in pages. The route planning algorithm will need multiple requests instead of just one. The fragements of the pages that can be retrieved are however highly cacheable.}
%    \label{fig:lc}
%\end{figure}
%

%%% EXPLAIN:
%%%
The expressiveness of a server affects the way logs can be gathered.
We have shown in previous sections that the query logs of a \emph{high expressive server}, such as the iRail API, are interesting: each request contains an entire query which can be interpreted as a travel intention.
The possibility that two requests are exactly the same is low, as there are many URLs which can be requested.
Nevertheless, we cannot fully guarantee that each HTTP GET request to the server will trigger a log entry, due to caching mechanisms on the Web~\cite{fielding}, which might lead to a false representation.

%intermodality, features and availability
Hosting a route planning API as the only way to publish transport data comes with three identified limitations, as the server will need to handle the requests from different use cases with different needs:
\begin{enumerate}
  \item When an application developer would like a \emph{new feature}, such as taking wheelchair accessibility information into account, the feature would have to be implemented on the server of the data publisher
  \item Keeping the server \emph{high available} is costly, as any question can be asked by anyone for any purpose.
  \item Federated querying, which would allow for \emph{intermodal} route planning for route planning APIs, is unexistent up to date.
\end{enumerate}

% GTFS
In order to overcome these limitations, the General Transit Feed Specification (GTFS)\footnote{\url{https://developers.google.com/transit/gtfs/reference}} can be used. 
GTFS is a compressed ZIP-file containing a couple of CSV files, describing the rules for when a public transit vehicle will pass by on a certain location.
It is supported among all current open source route planning software systems and it is used in products/apps such as \emph{CityMapper}, \emph{Ally}, \emph{Navitia.io}, \emph{Google Maps} and \emph{Bing Maps}.
%Persistence of the identifiers used within these datasets, is not a requirement, neither is it an ambition of the format\footnote{\url{https://groups.google.com/forum/#!msg/gtfs-changes/Z8Mf31MaZms/8Hc9F4psAQAJ}}.
%The goal of the format is to  an exchange format which specific software packages can use to transform it into their format of choice.
It succesfully enabled reuse for intermodal travel, engineers can rely on the data dumps even if the servers of the transit agency are offline and there is no limitation to the features that can be implemented.
The logs are however lost.

In \cref{fig:LDFAxis2} we illustrate these two options as two extremes, with other options that are yet to be discovered.
When a \emph{rather low expressive} server only allows to set e.g., a departure station and a departure time, then the server cannot log the arrival station, yet the client is still able to plan a route by executing the algorithm on the client-side~\cite{lc}.
Again, we are not able to rely on the query logs.

\section{Publishing query logs}
\label{sec:publishingquerylogs}

\todo{When the expressiveness of the servers is lower in order to maximize the reuse of the data, such as in the case of Linked~Connections or a GTFS~datadump, we suggest to, instead of logging each GET-request, to have an analytics server that gathers all the logs.}

\todo{Also in USEWOD2014 there was a paper on LDF and how we could know which SPARQL queries needed to be solved}

\todo{As of the 17th of December 2015, iRail publishes the most recent 1000 requests done on the API as open data, each second, at \url{http://api.irail.be/logs/}.
This amounts today to an average of 86k queries to the API per day, as the API gained popularity thanks to apps like \emph{BeTrains}\footnote{\url{https://play.google.com/store/apps/details?id=tof.cv.mpp}} and \emph{Railer}\footnote{\url{http://railer.be/}}.
On average, 14,357 of these are valid route planning queries (other queries include requesting departures in a station, status of a vehicle, or a list of all stations).
If each query would amount to indeed one passenger, this would today be equal to almost 2\% of all passengers.}

\section{Conclusion and discussion}
\label{sec:conclusion}

The contribution of this paper is twofold.
For the first time, we studied query logs to find travel patterns.
Due to lack of information we could not evaluate our results, yet the visualizations look promising...
There are obvious caveats associated with the use of such data as proxy for actual statistical counts. 
For instance, the data only captures an intention of a passenger: it's unsure whether the person actually took the train.
Furthermore, different requests could be done by one person with an intention to travel.
On top of that, our sample used for this paper can only represent a maximum of 0.4\% of the daily traffic flow.

The second contribution is our position that we suggest to decouple the query logs from the query execution.

% Fix spacing after References header (as line 1308 of sig-alternate.cls breaks it)
\let\oldsection\section
\renewcommand{\section}[2][1]{\oldsection{#1}\vspace{-3pt}}

\bibliographystyle{abbrv}
\bibliography{refs}
\end{document}
